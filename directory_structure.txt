Структура папки: C:\Users\user\Downloads\log-processor\log-processor

- README.md
    [Содержимое файла: README.md]
    · Программа корректно работает и выводит статистику логов.
    · Используются горутины для параллельной обработки (3 штуки).
    · Данные передаются между этапами через каналы.
    · Реализован паттерн Worker Pool с синхронизацией.
    · Есть обработка ошибок без остановки программы.
    · Код читаемый, с комментариями к основным функциям.
    · Присутствует README с инструкцией по запуску .
    · Программа запускается через go run main.go testdata/logs.csv и корректно обрабатывает тестовые данные.
    · Выводится читаемая статистика с количеством запросов, ошибок и средним временем ответа.
    
    Добавил библиотеку sort для сортировки записей при подсчете самых частых IP.
    
    P.S. Просьба пояснить необходимость наличия функции filterLogs. Она должна быть встроена в пайплайн, но ее роль здесь не совсем очевидна.
    Статистика и по корректным, и по ошибочным запросам может быть собрана в блоке calculateStats, а при фильтрации filterLogs мы будем
    "отсекать" часть логов. Если бы нужна была обработка только ошибок - все понятно. Но при необходимости вывода статистики по всем логам - не совсем.
    
    Пример выполнения программы:
    Ввод:
    `go run -race main.go processor.go testdata/logs.csv`
    Вывод:
    `Статистика:`
    `Поступило запросов: 15`
    `Из них с ошибкой: 8`
    `Среднее время отклика: 665.33 ms`
    `Наиболее частые IP:`
    `192.168.1.100: 5 раз(а)`
    `192.168.1.102: 2 раз(а)`
    `192.168.1.103: 1 раз(а)`
    `192.168.1.105: 1 раз(а)`
    `192.168.1.107: 1 раз(а)`
- go.mod
    [Содержимое файла: go.mod]
    module github.com/MeSeurus/log-processor
    
    go 1.25.3
- main.go
    [Содержимое файла: main.go]
    package main
    
    import (
    	"context"
    	"fmt"
    	"log"
    	"os"
    )
    
    // Основной исполняемый код
    func main() {
    
    	// Валидация корректности вводимых стартовых данных
    	// Второй аргумент в запросе будет указывать на путь файла с тестовыми данными (см. README)
    	if len(os.Args) < 2 {
    		fmt.Println("Usage:", os.Args[0], "<filename>")
    		os.Exit(1)
    	}
    	filename := os.Args[1]
    
    	// Создадим контекст для управления всеми действиями
    	ctx, cancel := context.WithCancel(context.Background())
    	defer cancel()
    
    	// Начинаем чтение файла
    	inputChan, err := readLogs(filename)
    	if err != nil {
    		log.Fatalf("Ошибка при чтении файла: %v", err)
    	}
    
    	// Обрабатываем данные в пуле воркеров
    	processedChan := processLogs(ctx, inputChan, 3)
    
    	// Подсчитываем статистику по всем запросам
    	allStats := calculateStats(processedChan)
    
    	// Выводим результаты
    	fmt.Println("Статистика:")
    	fmt.Printf("Поступило запросов: %d\n", allStats.TotalRequests)
    	fmt.Printf("Из них с ошибкой: %d\n", allStats.ErrorCount)
    	fmt.Printf("Среднее время отклика: %.2f ms\n", allStats.AverageRespTime)
    
    	printTopIPs(allStats.RequestsByIP, 5)
    }
- processor.go
    [Содержимое файла: processor.go]
    package main
    
    import (
    	"bufio"
    	"context"
    	"fmt"
    	"log"
    	"os"
    	"sort"
    	"strconv"
    	"strings"
    	"sync"
    )
    
    type LogEntry struct {
    	Timestamp    string // Время события ("2024-01-15 10:30:00")
    	IP           string // IP адрес клиента
    	Method       string // Метод HTTP-запроса (GET, POST и др.)
    	URL          string // Запрашиваемый URL
    	StatusCode   int    // HTTP-статус-код (200, 404 и др.)
    	ResponseTime int    // Время ответа сервера в мс
    }
    
    type Statistics struct {
    	TotalRequests   int            // Всего запросов
    	ErrorCount      int            // Количество ошибок (≥ 400)
    	RequestsByIP    map[string]int // Кол-во запросов по каждому IP
    	AverageRespTime float64        // Среднее время ответа
    }
    
    // Читаем входные данные и парсим с обработкой ошибок
    func readLogs(filename string) (<-chan LogEntry, error) {
    	ch := make(chan LogEntry)
    
    	// Запускаем горутину для обработки
    	go func() {
    		defer close(ch)
    
    		file, err := os.Open(filename)
    		if err != nil {
    			log.Fatalf("Ошибка открытия файла: %v", err)
    		}
    		defer file.Close()
    
    		scanner := bufio.NewScanner(file)
    		for scanner.Scan() {
    			line := scanner.Text()
    			entry, err := parseLogLine(line)
    			if err != nil {
    				log.Printf("Ошибка парсинга строки '%s': %v\n", line, err)
    				continue
    			}
    			ch <- entry
    		}
    
    		erro := scanner.Err()
    		if erro != nil {
    			log.Fatalf("Ошибка чтения файла: %v", erro)
    		}
    	}()
    
    	return ch, nil
    }
    
    // Обработка логов с использованием worker pool
    func processLogs(ctx context.Context, input <-chan LogEntry, numWorkers int) <-chan LogEntry {
    	outputCh := make(chan LogEntry)
    
    	// Добавляем блок синхронизации
    	var wg sync.WaitGroup
    	wg.Add(numWorkers)
    
    	// Запускаем несколько горутин для работы с входящими строками и отправляем далее по пайплайну
    	for range numWorkers {
    		go func() {
    			defer wg.Done()
    			for {
    				select {
    				case entry, ok := <-input:
    					if !ok {
    						return
    					}
    					outputCh <- entry
    				case <-ctx.Done():
    					return
    				}
    			}
    		}()
    	}
    
    	go func() {
    		wg.Wait()
    		close(outputCh)
    	}()
    
    	return outputCh
    }
    
    // Пример возможной фильтрации логов
    // Не совсем понятно зачем она нужна в контексте задания, если можно посчитать количество
    // ошибочных записей прямо в блоке обработки (см. далее, метод calculateStats)
    func filterLogs(input <-chan LogEntry, minStatus int) <-chan LogEntry {
    	outputCh := make(chan LogEntry)
    
    	// Стартуем горутину для фильтрации только ошибочных логов
    	go func() {
    		defer close(outputCh)
    		for entry := range input {
    			if entry.StatusCode >= minStatus {
    				outputCh <- entry
    			}
    		}
    	}()
    
    	return outputCh
    }
    
    /**
    * Запись данных в структуру для учета статистики
     */
    func calculateStats(input <-chan LogEntry) Statistics {
    	stats := Statistics{
    		TotalRequests:   0,
    		ErrorCount:      0,
    		RequestsByIP:    make(map[string]int),
    		AverageRespTime: 0,
    	}
    
    	totalResponseTime := 0
    
    	for entry := range input {
    		stats.TotalRequests++
    		if entry.StatusCode >= 400 {
    			stats.ErrorCount++
    		}
    		stats.RequestsByIP[entry.IP]++
    		totalResponseTime += entry.ResponseTime
    	}
    
    	if stats.TotalRequests > 0 {
    		stats.AverageRespTime = float64(totalResponseTime) / float64(stats.TotalRequests)
    	}
    
    	return stats
    }
    
    // Вспомогательный метод для парсинга данных в запись LogEntry
    func parseLogLine(line string) (LogEntry, error) {
    	// Формат данных можно поделить по запятой, на основании чего и строится обработка
    	fields := strings.Split(line, ",")
    	if len(fields) != 6 {
    		return LogEntry{}, fmt.Errorf("некорректное количество полей в строке: %s", line)
    	}
    
    	statusCode, err := strconv.Atoi(fields[4])
    	if err != nil {
    		return LogEntry{}, fmt.Errorf("невозможно преобразовать статус-код: %v", err)
    	}
    
    	responseTime, err := strconv.Atoi(fields[5])
    	if err != nil {
    		return LogEntry{}, fmt.Errorf("невозможно преобразовать время ответа: %v", err)
    	}
    
    	// Вывести лог по распарсенной строке
    	return LogEntry{
    		Timestamp:    fields[0],
    		IP:           fields[1],
    		Method:       fields[2],
    		URL:          fields[3],
    		StatusCode:   statusCode,
    		ResponseTime: responseTime,
    	}, nil
    }
    
    // Преобразование и вывод мапы с IP адресами
    func printTopIPs(requestsByIP map[string]int, n int) {
    	// Преобразуем карту в срез для сортировки
    	type pair struct {
    		ip    string
    		count int
    	}
    	pairs := make([]pair, 0, len(requestsByIP))
    	for ip, count := range requestsByIP {
    		pairs = append(pairs, pair{ip, count})
    	}
    	// Сортируем по убыванию количества запросов
    	sort.Slice(pairs, func(i, j int) bool {
    		return pairs[i].count > pairs[j].count
    	})
    	// Берём топ-N IP-адресов
    	topLimit := n
    	if len(pairs) < n {
    		topLimit = len(pairs)
    	}
    	// Выводим результат
    	fmt.Println("Наиболее частые IP:")
    	for i := 0; i < topLimit; i++ {
    		fmt.Printf("%s: %d раз(а)\n", pairs[i].ip, pairs[i].count)
    	}
    }
[Папка] testdata/
    - logs.csv
        [Содержимое файла: logs.csv]
        2024-01-15 10:29:59,192.168.1.100,GET,/api/users,200,150
        2024-01-15 10:30:00,192.168.1.101,POST,/api/users,201,200
        2024-01-15 10:30:01,192.168.1.100,GET,/api/users,404,50
        2024-01-15 10:30:02,192.168.1.102,GET,/api/products,500,1500
        2024-01-15 10:30:03,192.168.1.100,GET,/api/orders,200,100
        2024-01-15 10:30:04,192.168.1.103,POST,/api/orders,201,250
        2024-01-15 10:30:05,192.168.1.104,GET,/api/health,200,10
        2024-01-15 10:30:06,192.168.1.105,GET,/api/reports,502,2000
        2024-01-15 10:30:07,192.168.1.100,POST,/api/login,400,80
        2024-01-15 10:30:08,192.168.1.106,GET,/api/invalid,404,40
        2024-01-15 10:30:09,192.168.1.107,DELETE,/api/users/789,403,25
        2024-01-15 10:30:10,192.168.1.100,POST,/api/profile,200,180
        2024-01-15 10:30:11,192.168.1.108,GET,/api/timeout,504,5000
        2024-01-15 10:30:12,192.168.1.102,POST,/api/upload,413,300
        2024-01-15 10:30:13,192.168.1.109,GET,/api/data,200,95
